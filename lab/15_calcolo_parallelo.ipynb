{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcolo parallelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Thread e processi](#thread_processi) <br>\n",
    "2. [Web scraping](#scraping)<br>\n",
    "3. [Programmazione sequenziale](#sequenziale)<br>\n",
    "4. [Programmazione concorrente - *multithreading*](#multithreading)<br>\n",
    "    3.1 [La classe `Thread`](#thread)<br>\n",
    "    3.2 [Confrontare i tempi di esecuzione](#tempi)<br>\n",
    "5. [Programmazione concorrente - *multiprocessing*](#multiprocessing)<br>\n",
    "    4.1 [La classe `Process`](#process)<br>\n",
    "    4.2 [La classe `Pool`](#pool)<br>\n",
    "6. [Scegliere gli iperparametri ottimali](#iperparametri)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import threading\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thread e processi <a id=thread_processi> </a>\n",
    "\n",
    "Il **processo** è l'istanza di esecuzione di un'applicazione. Ad esempio, quando eseguiamo `jupyter notebook` da terminale, stiamo avviando un processo. Ciascun processo risiede in aree di memoria differenti e, per comunicare tra loro, devono utilizzare canali come *file, pipe, code o socket*.\n",
    "\n",
    "Ciascun processo può contenere più **thread**, di cui uno viene chiamato *thread primario*. I thread afferenti ad uno stesso processo condividono la medesima area di memoria, possono leggere e scrivere le stesse variabili e di conseguenza possono interferire l'uno con l'altro. \n",
    "\n",
    "Tipicamente, se si vuole parallelizzare l'esecuzione di un problema, si utilizza il *multithreading*, per permettere la cooperazione dei singoli thread nella stessa area di memoria. L'esecuzione *multithreading* generalmente garantisce performance migliori rispetto al *multiprocessing* (area di memoria condivisa e non duplicata, comunicazione inter-thread più veloce), tuttavia bisogna stare attenti a come i singoli *thread* accedono alle variabili, per evitare sovrascritture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Web scraping <a id=scraping> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricamento delle librerie per il web scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrarre il contenuto di una pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIZIO]\n",
      "URL: https://www.didattica.unipd.it/off/2016/LT/SC/SC2094/000ZZ/SCP4063754/N0\n",
      "ID processo: 2912\n",
      "Nome processo: MainProcess\n",
      "Nomethread: MainThread\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.didattica.unipd.it/off/2016/LT/SC/SC2094/000ZZ/SCP4063754/N0\"\n",
    "\n",
    "id_processo = os.getpid()\n",
    "nome_processo = mp.current_process().name\n",
    "nome_thread = threading.current_thread().name\n",
    "print(\"[INIZIO]\\nURL: {}\\nID processo: {}\\nNome processo: {}\\nNome\"\n",
    "        \"thread: {}\\n\".format(url, id_processo, nome_processo, nome_thread))\n",
    "\n",
    "risposta = requests.get(url)\n",
    "contenuto = BeautifulSoup(risposta.content, \"lxml\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime 5 righe non vuote:\n",
      "Didattica - Università degli Studi di Padova\n",
      "Vai alla navigazione\n",
      "Unipd.it\n",
      "Rubrica\n",
      "IT\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "righe_non_vuote = [c for c in contenuto.split(\"\\n\") if c.strip()]\n",
    "\n",
    "print(\"Prime {} righe non vuote:\".format(N))\n",
    "for riga in righe_non_vuote[:N]:\n",
    "    print(\"{}\".format(riga))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Programmazione sequenziale <a id=sequenziale> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS = [\n",
    "    \"https://www.didattica.unipd.it/off/2016/LT/SC/SC2094/000ZZ/SCP4063754/N0\",\n",
    "    \"https://stackoverflow.com/questions/3044580/multiprocessing-vs-threading-python\",\n",
    "    \"https://docs.python.org/3.6/library/threading.html\",\n",
    "    \"https://docs.python.org/3.6/library/multiprocessing.html\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con il comando successivo, estraiamo il contenuto delle URL inserite nella lista precedente e ne cronometriamo il tempo di esecuzione (utilizzando un ciclo for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durata: 2.91s\n"
     ]
    }
   ],
   "source": [
    "inizio = time.time()\n",
    "contenuti = list()\n",
    "\n",
    "for url in URLS:\n",
    "    risposta = requests.get(url)\n",
    "    contenuto = BeautifulSoup(risposta.content, \"lxml\").get_text()\n",
    "    contenuti.append(contenuto)\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ripetiamo la stessa operazione utilizzando la *list comprehension*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = time.time()\n",
    "\n",
    "contenuti = [BeautifulSoup(requests.get(url).content, \"lxml\").get_text() for url in URLS]\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Programmazione concorrente - *multithreading* <a id=multithreading> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 La classe [Thread](https://docs.python.org/3.6/library/threading.html#threading.Thread) <a id=thread> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otteniamo il contenuto delle url elencate al punto precedente utilizzando la programmazione in *multithreading*, tramite la classe `Thread`. Per farlo, avremo bisogno di inserire all'interno di una funzione i comandi che effettuano il *web scraping* della singola url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contenuto_url(url, coda=None, verboso=True):\n",
    "    id_processo = os.getpid()\n",
    "    nome_processo = mp.current_process().name\n",
    "    nome_thread = threading.current_thread().name\n",
    "\n",
    "    if verboso:\n",
    "        print(\"[INIZIO]\\nURL: {}\\nID processo: {}\\nNome processo: {}\\nNome\"\n",
    "        \"thread: {}\\n\".format(url, id_processo, nome_processo, nome_thread))\n",
    "        \n",
    "    # il blocco try/Except consente di \"intercettare\" eccezioni/errori\n",
    "    # nell'esecuzione, in modo da indicare le cause dell'arresto.\n",
    "    try:\n",
    "        risposta = requests.get(url)\n",
    "        testo = BeautifulSoup(risposta.content, \"lxml\").get_text()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(\"HTTP Error:\", err)\n",
    "    except requests.exceptions.ConnectionError as err:\n",
    "        print(\"Connection Error:\", err)\n",
    "    except requests.exceptions.Timeout as err:\n",
    "        print(\"Timeout Error:\", err)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"Request Error\", err)\n",
    "\n",
    "    if verboso:\n",
    "        print(\"[FINE]\\nURL: {}\\nID processo: {}\\nNome processo: {}\\nNome\"\n",
    "        \"thread: {}\\n\".format(url, id_processo, nome_processo, nome_thread))\n",
    "\n",
    "    if coda is None:\n",
    "        return testo\n",
    "    else:\n",
    "        coda.put(testo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verboso = True\n",
    "\n",
    "inizio = time.time()\n",
    "\n",
    "# istanziamo una coda, alla quale tutti i thread hanno accesso \n",
    "# e possono depositare i risultati ottenuti\n",
    "coda = mp.Queue()\n",
    "\n",
    "# istanziamo N=5 threads\n",
    "threads = [threading.Thread(target=contenuto_url, args=(url,),\n",
    "    kwargs={\"coda\": coda, \"verboso\": verboso}) for url in URLS]\n",
    "\n",
    "# avviamo ciascun thread\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# \n",
    "contenuti = [coda.get() for t in threads]\n",
    "\n",
    "for t in threads:\n",
    "    t.join() # blocca il MainThread finché t non è completato\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Confrontare i tempi di esecuzione <a id=tempi> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo di esecuzione approccio sequenziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contenuto_urls_sequenziale(urls, verboso=False):\n",
    "    for url in urls:\n",
    "        contenuti = [contenuto_url(url, verboso=verboso) for url in urls]\n",
    "    return contenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit -r 5 -n 1 contenuto_urls_sequenziale(URLS, verboso=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo di esecuzione approccio multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contenuto_urls_threading(urls, verboso=True):\n",
    "    coda = mp.Queue()\n",
    "\n",
    "    threads = [threading.Thread(target=contenuto_url, args=(url,),\n",
    "        kwargs={\"coda\": coda, \"verboso\": verboso}) for url in urls]\n",
    "\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "\n",
    "    contenuti = [coda.get() for t in threads]\n",
    "\n",
    "    for t in threads:\n",
    "        t.join() # blocca il MainThread finché t non è completato\n",
    "\n",
    "    return contenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%timeit -r 5 -n 1 contenuto_urls_threading(URLS, verboso=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Programmazione concorrente - *multiprocessing* <a id=multiprocessing> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sia la classe `multiprocessing.Process` che la `multiprocessing.Pool` utilizzano diversi processi per parallelizzare l'esecuzione.\n",
    " \n",
    "* La `Pool` distribuisce i task da eseguire su una coda FIFO (First In First Out), mappa l'input ricevuto sui processori disponibili e colleziona gli output in forma di lista o array. Solo i processi attualmente in esecuzione sono contenuti in memoria.\n",
    "\n",
    "* La `Process` istanzia tutti i processi in memoria.\n",
    "\n",
    "Quando è meglio usare l'uno o l'altro?\n",
    "* Nel caso in cui dovessimo eseguire molti task ripetitivi, è consigliabile utilizzare `Pool`, che si occuperà di associare ogni task ad un processore;\n",
    "* Se abbiamo un numero ridotto di task, ciascuno dei quali viene eseguito solo una volta, ha senso usare un `Process` per ciascuno di essi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_CPU = mp.cpu_count()\n",
    "\n",
    "print(\"# CPU: {}\".format(N_CPU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 La classe [Process](https://docs.python.org/3.6/library/multiprocessing.html?highlight=process#multiprocessing.Process) <a id=process> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.scraping import contenuto_url, contenuto_urls_multiprocessing\n",
    "print(inspect.getsource(contenuto_urls_multiprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = time.time()\n",
    "\n",
    "contenuti = contenuto_urls_multiprocessing(URLS)\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo il *comando magico* `%timeit` per calcolare il tempo di esecuzione nel caso di approccio *multiprocess* con la funzione `contenuto_urls_multiprocessing(URLS, verboso=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 5 -n 1 contenuto_urls_multiprocessing(URLS, verboso=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 La classe [Pool](https://docs.python.org/3.6/library/multiprocessing.html?highlight=process#multiprocessing.pool.Pool) <a id=pool> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = time.time()\n",
    "\n",
    "pool = mp.Pool(processes=N_CPU)\n",
    "contenuti = [pool.map(contenuto_url, URLS)]\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggere il data set\n",
    "tweets = pd.read_csv(\"datasets/twitter/train.csv\", encoding=\"latin\")[\"SentimentText\"].tolist()\n",
    "# creare il tokenizer\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "# creare lo stemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# creare una funzione per dividere il tweet in token ridotti alla radice\n",
    "def tweet_analyzer(tweet): return [stemmer.stem(t) for t in tokenizer.tokenize(tweet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approccio sequenziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = time.time()\n",
    "\n",
    "tweets_preproc = [tweet_analyzer(tweet) for tweet in tweets]\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))\n",
    "\n",
    "print(tweets_preproc[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approccio parallelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo la classe `Pool` per parallelizzare l'analisi dei tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = time.time()\n",
    "\n",
    "pool = mp.Pool(processes=N_CPU)\n",
    "tweets_preproc = pool.map(tweet_analyzer, tweets)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))\n",
    "\n",
    "print(tweets_preproc[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linee guida generali sulla scelta della classe più appropriata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. **Thread**: numero di task medio-basso, molte operazioni di I/O, utilizzo della CPU relativamente basso;\n",
    ">2. **Process**: numero di task medio-basso, utilizzo intensivo della CPU;\n",
    ">3. **Pool**: numero di task alto, utilizzo intensivo della CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Scegliere gli iperparametri ottimali <a id=iperparametri> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confronteremo ora le performance dell'approccio sequenziale e quelle dell'approccio multiprocesso nella ricerca degli iperparametri ottimali, da ricercare all'interno di una griglia da noi specificata.\n",
    "\n",
    "Questa è un'operazione facilmente parallelizzabile che sfrutta la potenza del calcolo parallelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msbd.preprocessamento import OttenereDummy\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leggere il data set\n",
    "dati = pd.read_csv(\"datasets/titanic/train.csv\")\n",
    "\n",
    "# dividere la X dalla y\n",
    "X, y = dati.drop(columns=\"Survived\").copy(), dati[\"Survived\"].copy()\n",
    "\n",
    "# definire una pipeline di classificazione\n",
    "clf = Pipeline([\n",
    "    (\"ottenere_dummy\", OttenereDummy(drop_first=True)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "    (\"tree\", DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# griglia su cui eseguire la ricerca\n",
    "griglia = {\n",
    "    'tree__max_depth': np.arange(1, 18),\n",
    "    'tree__min_samples_leaf': 2 ** np.arange(9),\n",
    "}\n",
    "\n",
    "# dividere i dati in training e test\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "train_indices, val_indices = next(splitter.split(X, y))\n",
    "X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "X_val, y_val = X.iloc[val_indices], y.iloc[val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approccio sequenziale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effettuiamo una *grid search* come visto nel notebook [Alberi di decisione](11_alberi_di_decisione.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "inizio = time.time()\n",
    "\n",
    "risultati = []\n",
    "\n",
    "for params in tqdm.tqdm(ParameterGrid(griglia)):\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    params[\"accuracy_score\"] = accuracy_score(y_val, y_pred)\n",
    "    risultati.append(params)\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))\n",
    "\n",
    "risultati = pd.DataFrame(risultati)\n",
    "risultati.sort_values(\"accuracy_score\", ascending=False, inplace=True)\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "\n",
    "risultati.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approccio parallelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molti dei metodi offerti da `sklearn` sfruttano il calcolo parallelo senza il bisogno di specificare esplicitamente *processi*, *thread* o *pool*, ma semplicemente valorizzando alcuni loro parametri.\n",
    "\n",
    "Ad esempio, `sklearn.model_selection.GridSearchCV` permette di specificare tramite il parametro `n_jobs` il numero di processi da utilizzare per la ricerca degli iperparametri ottimali, utilizzando quanto già fatto finora, ad esempio all'interno di una *pipeline* o di un classificatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = time.time()\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=clf, \n",
    "    param_grid=griglia,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=splitter, \n",
    "    n_jobs=N_CPU, \n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "gscv.fit(X, y)\n",
    "\n",
    "fine = time.time()\n",
    "print(\"Durata: {:.2f}s\".format(fine - inizio))\n",
    "\n",
    "risultati = pd.DataFrame(gscv.cv_results_)\n",
    "risultati.sort_values(\"split0_test_score\", ascending=False, inplace=True)\n",
    "risultati.reset_index(drop=True, inplace=True)\n",
    "\n",
    "risultati.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
